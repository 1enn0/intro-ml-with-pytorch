{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continuous-democracy",
   "metadata": {},
   "source": [
    "<img src=\"https://www.onemodel.co/hs-fs/hubfs/U4SezaC-1.png?width=536&name=U4SezaC-1.png\" width=\"300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-rolling",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "## Goal\n",
    "* basic high-level understanding of machine learning\n",
    "* understand the importance of data\n",
    "* \n",
    "\n",
    "**Attribution.** Most of the material in this document is taken from the fast.ai course [Practical Deep Learning for Coders](https://course.fast.ai/), especially the [01_intro](https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb) and the [04_mnist_basics](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb) notebooks.\n",
    "In you are interested into machine learning, I highly recommend to check it out! They cover a lot of fundamentals of neural networks and machine learning in general in more depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-economy",
   "metadata": {},
   "source": [
    "### Artificial Neurons\n",
    "\n",
    "In 1943, Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, developed a mathematical model of an artificial neuron.\n",
    "\n",
    "They realized that a simplified model of a real neuron could be represented using simple addition and thresholding.\n",
    "\n",
    "\n",
    "<img src=\"../assets/images/chapter7_neuron.png\" width=\"500px\"/><a href=\"https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb#scrollTo=tewCOeL7eHhp\">(Image Source)</a>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "A neural networks is a computing system inspired by biological brains, made up by a collection of connected artifical neurons: \n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg\" width=\"300px\"/><a href=\"https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg\">(Image Source)</a>\n",
    "\n",
    "The term _deep learning_ just refers to neural networks with a lot of layers.\n",
    "\n",
    "Although neural networks have been around for a long time, they have only recently started living up to their potential. This is in part due to some misunderstanding of the theoretical issues (in the early years only very few layers were used) but maybe more importantly due to the increased computing power and data availability as well as algorithmic tweaks that allow for faster and easier training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-fence",
   "metadata": {},
   "source": [
    "## What is _Machine Learning_?\n",
    "\n",
    "Deep learning and neural networks are just specific areas in the more general discipline of _machine learning_.\n",
    "\n",
    "_Machine Learning_ in general is, like regular programming, a way to get computers to complete a specific task. But how would we use regular programming to e.g. recognize dogs versus cats in photos? We would have to write down for the computer the exact steps necessary to complete the task.\n",
    "\n",
    "### A Traditional Program\n",
    "\n",
    "Normally, it's easy enough for us to write down the steps to complete a task when we're writing a program. We just think about the steps we'd take if we had to do the task by hand, and then we translate them into code. For instance, we can write a function that sorts a list. In general, we'd write a function that looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-hebrew",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img id=\"traditional_program\" alt=\"A Traditional Program\" src=\"../assets/images/traditional-program.svg\" width=\"500px\"/>\n",
    "<a href=\"https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb\">(Image Source)</a>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-steel",
   "metadata": {},
   "source": [
    "For recognizing objects in a photo, this is a bit tricky: what _are_ the exact steps we take when we recognize an object in a picture? We really don't know, since it all happens in our brain without us being consciously aware of it!\n",
    "\n",
    "Right back at the dawn of computing, in 1949, an IBM researcher named Arthur Samuel started working on a different way to get computers to complete tasks, which he called machine learning. In his classic 1962 essay _Artificial Intelligence: A Frontier of Automation_, he wrote:\n",
    "\n",
    "> \"Programming a computer for such computations is, at best, a difficult task, not primarily because of any inherent complexity in the computer itself but, rather, because of the need to spell out every minute step of the process in the most exasperating detail. Computers, as any programmer will tell you, are giant morons, not giant brains.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-organic",
   "metadata": {},
   "source": [
    "### Using Weight Assignment\n",
    "\n",
    "His basic idea was this: instead of telling the computer the exact steps required to solve a problem, show it examples of the problem to solve, and let it figure out how to solve it itself. This turned out to be very effective: by 1961 his checkers-playing program had learned so much that it beat the Connecticut state champion! Here's how he described his idea (from the same essay as above):\n",
    "\n",
    "> \"Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.\"\n",
    "\n",
    "The key concepts embedded in this statement are:\n",
    "* The idea of a _weight assignment_\n",
    "* The fact that every weight assignment has some _actual performance_\n",
    "* The requirement that there be an _automatic means_ of testing that performance\n",
    "* The need for a _mechanism_ (i.e. another automatic process) for improving the performance by changing the weight assignments\n",
    "\n",
    "Let us take these concepts one by one, in order to understand how they fit together in practice. First, we need to understand what Samuel means by a weight assignment.\n",
    "\n",
    "Weights are just variables, and a weight assignment is a particular choice of values for those variables. The program's inputs are values that it processes in order to produce its results—for instance, taking image pixels as inputs, and returning the classification \"dog\" as a result. The program's weight assignments are other values that define how the program will operate.\n",
    "\n",
    "Since they will affect the program they are in a sense another kind of input, so we will update our <a href=\"#traditional_program\">basic picture</a> to take this into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-motorcycle",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img id=\"weight_assignment\" alt=\"A Prgroam using Weight Assignment\" src=\"../assets/images/weight_assignment.svg\" width=\"500px\"/>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb\">(Image Source)</a>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-tracy",
   "metadata": {},
   "source": [
    "We've changed the name of our box from _program_ to _model_. This is to follow modern terminology and to reflect that the model is a special kind of program: it's one that can do many different things, depending on the weights. It can be implemented in many different ways.\n",
    "\n",
    "(By the way, what Samuel called _weights_ are most generally referred to as model _parameters_ these days, in case you have encountered that term. The term weights is reserved for a particular type of model parameter.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-washington",
   "metadata": {},
   "source": [
    "### Training a Machine Learning Model\n",
    "\n",
    "Next, Samuel said we need an automatic means of testing the effectiveness of any current weight assignment in terms of actual performance. In the case of his checkers program, the \"actual performance\" of a model would be how well it plays. And you could automatically test the performance of two models by setting them to play against each other, and seeing which one usually wins.\n",
    "\n",
    "Finally, he says we need *a mechanism for altering the weight assignment so as to maximize the performance*. For instance, we could look at the difference in weights between the winning model and the losing model, and adjust the weights a little further in the winning direction.\n",
    "\n",
    "We can now see why he said that such a procedure *could be made entirely automatic and... a machine so programmed would \"learn\" from its experience*. Learning would become entirely automatic when the adjustment of the weights was also automatic—when instead of us improving a model by adjusting its weights manually, we relied on an automated mechanism that produced adjustments based on performance.\n",
    "\n",
    "The following image <a href=\"#training_loop\">Training Loop</a> shows the full picture of Samuel's idea of training a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-grass",
   "metadata": {},
   "source": [
    "<img id=\"training_loop\" alt=\"Training a Machine Learning Model\" src=\"../assets/images/training_loop.svg\" width=\"600px\"/>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb\">(Image Source)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-grocery",
   "metadata": {},
   "source": [
    "Notice the distinction between the model's results (e.g., the moves in a checkers game) and its performance (e.g., whether it wins the game, or how quickly it wins).\n",
    "\n",
    "Also note that once the model is trained—that is, once we've chosen our final, best, favorite weight assignment—then we can think of the weights as being part of the model, since we're not varying them any more.\n",
    "\n",
    "Therefore, actually using a model after it's trained looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-salad",
   "metadata": {},
   "source": [
    "<img id=\"using_model\" alt=\"Using a Trained Model as a Program\" src=\"../assets/images/using_model.svg\" width=\"500px\"/>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb\">(Image Source)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-designer",
   "metadata": {},
   "source": [
    "This looks identical to our original diagram <a href=\"#traditional_program\">here</a>, just with the word _program_ replaced with _model_. This is an important insight: a trained model can be treated just like a regular computer program.\n",
    "\n",
    "Now we have a consice definition of **machine learning**: The training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-veteran",
   "metadata": {},
   "source": [
    "## What is a Neural Network?\n",
    "\n",
    "It's not too hard to imagine what the model might look like for a checkers program. There might be a range of checkers strategies encoded, and some kind of search mechanism, and then the weights could vary how strategies are selected, what parts of the board are focused on during a search, and so forth. But it's not at all obvious what the model might look like for an image recognition program, or for understanding text, or for many other interesting problems we might imagine.\n",
    "\n",
    "What we would like is some kind of function that is so flexible that it could be used to solve any given problem, just by varying its weights. Amazingly enough, this function actually exists! It's the _neural network_. \n",
    "\n",
    "That is, if you regard a neural network as a mathematical function, it turns out to be a function which is extremely flexible depending on its weights. A mathematical proof called the *universal approximation theorem* shows that this function can solve any problem to any level of accuracy, in theory. The fact that neural networks are so flexible means that, in practice, they are often a suitable kind of model, and you can focus your effort on the process of training them—that is, of finding good weight assignments.\n",
    "\n",
    "But what about that process?  One could imagine that you might need to find a new \"mechanism\" for automatically updating weights for every problem. This would be laborious. What we'd like here as well is a completely general way to update the weights of a neural network, to make it improve at any given task. Conveniently, this also exists!\n",
    "\n",
    "This is called *stochastic gradient descent* (SGD). You can have a look on how neural networks and SGD work in detail in the [fast.ai MNIST Basics notebook](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb). \n",
    "\n",
    "For now, however, we will instead use Samuel's own words: *We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-basket",
   "metadata": {},
   "source": [
    "In other words, to recap, a neural network is a particular kind of machine learning model, which fits right in to Samuel's original conception. Neural networks are special because they are highly flexible, which means they can solve an unusually wide range of problems just by finding the right weights. This is powerful, because stochastic gradient descent provides us a way to find those weight values automatically.\n",
    "\n",
    "Having zoomed out, let's now zoom back in and revisit our example image classification problem (cats vs. dogs) using Samuel's framework.\n",
    "\n",
    "Our inputs are the images. Our weights are the weights in the neural net. Our model is a neural net. Our results are the values that are calculated by the neural net, like \"dog\" or \"cat.\"\n",
    "\n",
    "What about the next piece, an *automatic means of testing the effectiveness of any current weight assignment in terms of actual performance*? Determining \"actual performance\" is easy enough: we can simply define our model's performance as its accuracy at predicting the correct answers.\n",
    "\n",
    "Putting this all together, and assuming that SGD is our mechanism for updating the weight assignments, we can see how our image classifier is a machine learning model, much like Samuel envisioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-respect",
   "metadata": {},
   "source": [
    "## A Bit of Deep Learning Jargon\n",
    "\n",
    "Samuel was working in the 1960s, and since then terminology has changed. Here is the modern deep learning terminology for all the pieces we have discussed:\n",
    "\n",
    "- The functional form of the *model* is called its *architecture* (but be careful—sometimes people use *model* as a synonym of *architecture*, so this can get confusing).\n",
    "- The *weights* are called *parameters*.\n",
    "- The *results* of the model are called *predictions*.\n",
    "- The *predictions* are calculated from the *independent variable*, which is the *data* not including the *labels*.\n",
    "- The measure of *performance* is called the *loss*.\n",
    "- The loss depends not only on the predictions, but also the correct *labels* (also known as *targets* or the *dependent variable*); e.g., \"dog\" or \"cat.\"\n",
    "\n",
    "After making these changes, our diagram <a href=\"#training_loop\">Training Loop</a> now looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-ballet",
   "metadata": {},
   "source": [
    "<img id=\"detailed_loop\" alt=\"Detailed Training Loop\" src=\"../assets/images/detailed_loop.svg\" width=\"600px\"/>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb\">(Image Source)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-ivory",
   "metadata": {},
   "source": [
    "## Limitations Inherent to Machine Learning\n",
    "\n",
    "From this picture we can now see some fundamental things about training a deep learning model:\n",
    "\n",
    "- A model **cannot be created without data**.\n",
    "- A model can only learn to operate on the patterns seen in the input data used to train it.\n",
    "- This learning approach only creates *predictions*, not recommended *actions*.\n",
    "- It's not enough to just have examples of input data; we need *labels* for that data too (e.g., pictures of dogs and cats aren't enough to train a model; we need a label for each one, saying which ones are dogs, and which are cats).\n",
    "\n",
    "Generally speaking, we've seen that most organizations that say they don't have enough data, actually mean they don't have enough *labeled* data. If any organization is interested in doing something in practice with a model, then presumably they have some inputs they plan to run their model against. And presumably they've been doing that some other way for a while (e.g., manually, or with some heuristic program), so they have data from those processes! \n",
    "\n",
    "For instance, a radiology practice will almost certainly have an archive of medical scans (since they need to be able to check how their patients are progressing over time), but those scans may not have structured labels containing a list of diagnoses or interventions (since radiologists generally create free-text natural language reports, not structured data). We'll be discussing labeling approaches a lot in this book, because it's such an important issue in practice.\n",
    "\n",
    "Since these kinds of machine learning models can only make *predictions* (i.e., attempt to replicate labels), this can result in a significant gap between organizational goals and model capabilities. \n",
    "\n",
    "For instance, in [this book](https://github.com/fastai/fastbook) you'll learn how to create a *recommendation system* that can predict what products a user might purchase. This is often used in e-commerce, such as to customize products shown on a home page by showing the highest-ranked items. But such a model is generally created by looking at a user and their buying history (*inputs*) and what they went on to buy or look at (*labels*), which means that the model is likely to tell you about products the user already has or already knows about, rather than new products that they are most likely to be interested in hearing about. \n",
    "\n",
    "That's very different to what, say, an expert at your local bookseller might do, where they ask questions to figure out your taste, and then tell you about authors or series that you've never heard of before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-hayes",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* overfitting/underfitting https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-block",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
